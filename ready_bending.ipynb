{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import DataFrame, read_csv\n",
    "import pandas as pd #this is how I usually import pandas\n",
    "import matplotlib.pyplot as plt #for plot\n",
    "import nltk\n",
    "#read_csv?\n",
    "Location = r'../twitter_data/train2017.tsv'\n",
    "df = pd.read_csv(Location,delimiter = '\\t',names=['id','id2','tag','text'])\n",
    "Location_res = r'../twitter_data/test2017.tsv'\n",
    "df_res = pd.read_csv(Location_res,delimiter = '\\t',names=['id','id2','tag','text'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "embeddings_dict = {}\n",
    "LocationEm = r'../lexica/datastories.twitter.50d.txt'\n",
    "\n",
    "f = open(LocationEm, \"r\", encoding=\"utf-8\")\n",
    "for i, line in enumerate(f):\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "\n",
    "    embeddings_dict[word] = coefs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 5.46301183e-03  2.78999411e-01 -8.24852148e-02  1.80607990e-01\n",
      "  1.00905951e-01  9.96525568e-02  4.89083537e-02 -1.39805510e-01\n",
      " -7.75500190e-02 -1.12685746e-01  3.54180146e+00  2.68113938e-03\n",
      "  1.35652053e-01 -6.42828509e-02  3.24504567e-01  1.16049263e-01\n",
      "  3.73348021e-01  3.57540445e-02 -2.92934892e-01 -2.32191929e-01\n",
      " -4.52620296e-01  1.32361255e-01 -1.37792321e-01 -3.32240220e-01\n",
      "  3.50964198e-02  1.87277529e-01  1.15544078e-01  3.72265644e-01\n",
      "  8.27924468e-02  9.91982963e-03  2.05813247e-01 -1.10658855e-01\n",
      " -2.31660895e-01  6.37561269e-02  1.31977628e-01  5.19303442e-01\n",
      "  1.96215478e-01 -6.43583516e-02 -6.53425169e-02  1.55938007e-01\n",
      " -1.43074651e-02  3.24202875e-01 -1.07908203e-02 -3.29545068e-02\n",
      " -1.23829233e-01 -1.19502533e-01  1.21920069e-01  4.68574341e-02\n",
      "  2.79921635e-01  4.31524261e-01]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "i = 0\n",
    "arr = []\n",
    "for line in df.text:\n",
    "    #print(line)\n",
    "    arr.append(np.zeros(50))\n",
    "    for word in line.split():\n",
    "        #print(word)\n",
    "        if word in embeddings_dict:\n",
    "            #print(word)\n",
    "            #print(embeddings_dict[word])\n",
    "            arr[i] += embeddings_dict[word] / len(line.split())\n",
    "        else:\n",
    "            arr[i] += arr[i] / len(line.split())\n",
    "            \n",
    "    i=i+1\n",
    "\n",
    "print(arr[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.15982510e-01  7.76607776e-03  3.16891655e-02  1.49863391e-01\n",
      "  5.57120000e-02  8.39913341e-02  2.11496163e-01  3.43869089e-02\n",
      " -1.13403105e-01 -1.04231240e-01  1.47661440e+00  4.04891932e-02\n",
      "  1.13429810e-01 -6.92927431e-02  1.54389035e-01  1.23486372e-02\n",
      "  8.72201356e-02 -1.63503689e-01 -9.42040957e-02 -1.48032653e-01\n",
      " -1.80759776e-01 -2.64197397e-02 -1.28508166e-01 -2.11720230e-01\n",
      " -1.19084175e-01  8.18159538e-02  9.66596881e-02  5.01785216e-02\n",
      "  1.29876690e-01 -8.70914609e-04 -3.12378035e-04 -6.51268095e-02\n",
      " -5.96635543e-02  4.81066174e-02  7.90529773e-02  1.57642382e-01\n",
      " -3.34516335e-02  1.56094579e-01  2.23312739e-02  1.82804416e-01\n",
      " -9.40397963e-02  1.59538731e-01  1.45523858e-02  3.02322120e-03\n",
      "  6.64231629e-02 -8.59527330e-02  2.32974548e-02 -6.97613692e-04\n",
      "  1.82046057e-01  1.24809337e-01]\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "arr_res = []\n",
    "for line in df_res.text:\n",
    "    arr_res.append(np.zeros(50))\n",
    "    for word in line.split():\n",
    "        #print(word)\n",
    "        if word in embeddings_dict:\n",
    "            #print(word)\n",
    "            #print(embeddings_dict[word])\n",
    "            arr_res[i] += embeddings_dict[word] / len(line.split())\n",
    "        else:\n",
    "            arr_res[i] += arr_res[i] / len(line.split())\n",
    "            #print(\"not found \"+ word)\n",
    "    i=i+1\n",
    "\n",
    "print(arr_res[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=None, n_neighbors=3, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "x = arr\n",
    "y = df.tag\n",
    "knn.fit(x , y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_pred = arr_res\n",
    "y_pred = knn.predict(x_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4485509605991534\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "Location = r'../twitter_data/SemEval2017_task4_subtaskA_test_english_gold.txt'\n",
    "df_cor = pd.read_csv(Location,delimiter = '\\t',names=['id','tag'])\n",
    "print(metrics.accuracy_score(df_cor.tag, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
